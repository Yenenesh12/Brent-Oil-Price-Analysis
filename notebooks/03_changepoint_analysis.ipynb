{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Change Point Analysis\n",
    "\n",
    "**Objective:** Implement and validate Bayesian change point detection model for Brent oil prices.\n",
    "\n",
    "**Contents:**\n",
    "1. Model Implementation\n",
    "2. MCMC Sampling\n",
    "3. Convergence Diagnostics\n",
    "4. Results Interpretation\n",
    "5. Event Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "sys.path.append('../src')\n",
    "from data_loader import BrentDataLoader, EventDataLoader\n",
    "from changepoint_model import BayesianChangePointModel\n",
    "from event_correlator import EventCorrelator\n",
    "\n",
    "os.makedirs(\"../outputs/figures\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/models\", exist_ok=True)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9011 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\Brent-Oil-Price-Analysis\\notebooks\\../src\\data_loader.py:36: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df['Date'] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed: 1987-05-20 00:00:00 to 2022-11-14 00:00:00\n",
      "Data points: 9010\n",
      "Date range: 1987-05-21T00:00:00.000000 to 2022-11-14T00:00:00.000000\n",
      "\n",
      "Data statistics:\n",
      "  Mean: 0.000179\n",
      "  Std: 0.025531\n",
      "  Min: -0.643699\n",
      "  Max: 0.412023\n"
     ]
    }
   ],
   "source": [
    "# Load data with correct path\n",
    "loader = BrentDataLoader(data_path='../data/events/BrentOilPrices.csv')\n",
    "df = loader.load_data()\n",
    "df = loader.preprocess()\n",
    "\n",
    "# Use log returns for change point detection\n",
    "data = df['Log_Returns'].dropna().values\n",
    "dates = df['Date'].iloc[1:].values  # Skip first row due to returns calculation\n",
    "\n",
    "print(f\"Data points: {len(data)}\")\n",
    "print(f\"Date range: {dates[0]} to {dates[-1]}\")\n",
    "print(f\"\\nData statistics:\")\n",
    "print(f\"  Mean: {data.mean():.6f}\")\n",
    "print(f\"  Std: {data.std():.6f}\")\n",
    "print(f\"  Min: {data.min():.6f}\")\n",
    "print(f\"  Max: {data.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and Fit Bayesian Change Point Model\n",
    "\n",
    "### Model Specification:\n",
    "\n",
    "We use a Bayesian change point model with the following structure:\n",
    "\n",
    "**Priors:**\n",
    "- τ (change point locations) ~ DiscreteUniform(0, n-1)\n",
    "- μ (segment means) ~ Normal(data_mean, 2*data_std)\n",
    "- σ (observation noise) ~ HalfNormal(data_std)\n",
    "\n",
    "**Likelihood:**\n",
    "- obs ~ Normal(μ[segment], σ)\n",
    "\n",
    "**Inference:**\n",
    "- MCMC sampling using NUTS (No-U-Turn Sampler)\n",
    "- Multiple chains for convergence assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Bayesian change point model with 3 change points...\n",
      "\n",
      "✓ Model built successfully\n",
      "\n",
      "Model structure:\n",
      "<pymc.model.core.Model object at 0x00000207F32AD6A0>\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "n_changepoints = 3\n",
    "print(f\"Building Bayesian change point model with {n_changepoints} change points...\")\n",
    "\n",
    "n_changepoints = 3\n",
    "model = BayesianChangePointModel(data, n_changepoints=n_changepoints)  # ← Uses 'data' from previous cell\n",
    "model.build_model()\n",
    "\n",
    "\n",
    "print(\"\\n✓ Model built successfully\")\n",
    "print(\"\\nModel structure:\")\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convergence Diagnostics\n",
    "\n",
    "Before interpreting results, we must verify that MCMC chains have converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "summary = model.get_changepoint_summary()\n",
    "print(\"\\n=== MCMC CONVERGENCE DIAGNOSTICS ===\")\n",
    "print(\"\\nParameter Summary:\")\n",
    "print(summary)\n",
    "\n",
    "# Check R-hat values\n",
    "print(\"\\n=== R-HAT ANALYSIS ===\")\n",
    "print(\"R-hat measures convergence across chains.\")\n",
    "print(\"Values < 1.01 indicate good convergence.\")\n",
    "print(\"\\nR-hat values:\")\n",
    "print(summary['r_hat'])\n",
    "\n",
    "if (summary['r_hat'] < 1.01).all():\n",
    "    print(\"\\n✓ All R-hat values < 1.01: EXCELLENT convergence\")\n",
    "elif (summary['r_hat'] < 1.05).all():\n",
    "    print(\"\\n✓ All R-hat values < 1.05: Good convergence\")\n",
    "else:\n",
    "    print(\"\\n⚠ Some R-hat values >= 1.05: Consider running more iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace diagnostics\n",
    "print(\"\\nGenerating trace plots...\")\n",
    "fig = model.plot_trace()\n",
    "plt.savefig(\"../outputs/figures/trace_plots.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Trace plots saved\")\n",
    "print(\"\\nTrace Plot Interpretation:\")\n",
    "print(\"  Left panels: Posterior distributions (should be smooth)\")\n",
    "print(\"  Right panels: MCMC traces (should look like 'fuzzy caterpillars')\")\n",
    "print(\"  Good mixing: Chains overlap and explore parameter space\")\n",
    "print(\"  Poor mixing: Chains stuck or trending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Change Point Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract change point locations\n",
    "tau_samples = trace.posterior['tau'].values.reshape(-1, n_changepoints)\n",
    "tau_mean = tau_samples.mean(axis=0).astype(int)\n",
    "tau_std = tau_samples.std(axis=0)\n",
    "\n",
    "print(\"\\n=== DETECTED CHANGE POINTS ===\")\n",
    "for i, (idx, std) in enumerate(zip(tau_mean, tau_std), 1):\n",
    "    date = pd.to_datetime(dates[idx])\n",
    "    print(f\"\\nChange Point {i}:\")\n",
    "    print(f\"  Index: {idx}\")\n",
    "    print(f\"  Date: {date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Uncertainty (std): {std:.1f} days\")\n",
    "    \n",
    "    # Get 95% credible interval\n",
    "    lower = np.percentile(tau_samples[:, i-1], 2.5)\n",
    "    upper = np.percentile(tau_samples[:, i-1], 97.5)\n",
    "    lower_date = pd.to_datetime(dates[int(lower)])\n",
    "    upper_date = pd.to_datetime(dates[int(upper)])\n",
    "    print(f\"  95% Credible Interval: {lower_date.strftime('%Y-%m-%d')} to {upper_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig = model.plot_results(dates=dates, figsize=(18, 10))\n",
    "plt.savefig(\"../outputs/figures/changepoint_results.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Change point results plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Event Correlation Analysis\n",
    "\n",
    "Now we correlate detected change points with geopolitical events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load events with correct path\n",
    "event_loader = EventDataLoader(events_path='../data/events/geopolitical_events.csv')\n",
    "events_df = event_loader.load_events()\n",
    "\n",
    "# Create correlator\n",
    "correlator = EventCorrelator(events_df, pd.Series(dates))\n",
    "\n",
    "# Correlate change points with events\n",
    "correlation_results = correlator.correlate_changepoints(tau_mean, window_days=60)\n",
    "\n",
    "print(\"\\n=== EVENT CORRELATION ANALYSIS ===\")\n",
    "print(f\"\\nSearching for events within ±60 days of each change point...\\n\")\n",
    "\n",
    "for result in correlation_results:\n",
    "    cp_date = result['changepoint_date']\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Change Point: {cp_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if result['events']:\n",
    "        print(f\"\\nFound {len(result['events'])} nearby events:\\n\")\n",
    "        for i, event in enumerate(result['events'][:5], 1):  # Show top 5\n",
    "            print(f\"{i}. {event['description']}\")\n",
    "            print(f\"   Date: {event['event_date'].strftime('%Y-%m-%d')}\")\n",
    "            print(f\"   Category: {event['category']}\")\n",
    "            print(f\"   Days from change point: {event['days_difference']}\")\n",
    "            print(f\"   Proximity score: {event['proximity_score']:.3f}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"\\n⚠ No events found within time window\")\n",
    "        print(\"   This change point may be driven by:\")\n",
    "        print(\"   - Gradual market dynamics\")\n",
    "        print(\"   - Multiple small events\")\n",
    "        print(\"   - Events not in our dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Interpretation\n",
    "\n",
    "### Model Performance:\n",
    "\n",
    "1. **Convergence:** [Check R-hat values above]\n",
    "2. **Change Points Detected:** [Number and dates]\n",
    "3. **Event Correlations:** [Summary of correlations]\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Structural Breaks Identified:**\n",
    "   - Model successfully identified major regime changes\n",
    "   - Change points align with known market events\n",
    "   - Uncertainty quantified through credible intervals\n",
    "\n",
    "2. **Event Correlations:**\n",
    "   - Strong temporal alignment with geopolitical events\n",
    "   - Multiple events may contribute to single change point\n",
    "   - Some change points lack clear event correlation\n",
    "\n",
    "3. **Limitations:**\n",
    "   - **Correlation ≠ Causation:** Temporal proximity doesn't prove causation\n",
    "   - **Model Assumptions:** Discrete change points may miss gradual transitions\n",
    "   - **Event Dataset:** May not capture all market-moving factors\n",
    "   - **Confounding Factors:** Multiple simultaneous influences\n",
    "\n",
    "### Business Implications:\n",
    "\n",
    "1. **Risk Management:**\n",
    "   - Identified high-volatility regimes\n",
    "   - Quantified uncertainty in regime transitions\n",
    "   - Historical patterns inform hedging strategies\n",
    "\n",
    "2. **Market Understanding:**\n",
    "   - Geopolitical events drive structural breaks\n",
    "   - Different regimes have different dynamics\n",
    "   - Event monitoring crucial for risk assessment\n",
    "\n",
    "3. **Forecasting Considerations:**\n",
    "   - Historical change points don't predict future ones\n",
    "   - Model identifies past regimes, not future breaks\n",
    "   - Continuous monitoring needed for new change points\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Operational:**\n",
    "   - Monitor geopolitical events closely\n",
    "   - Adjust risk exposure based on regime identification\n",
    "   - Update analysis quarterly with new data\n",
    "\n",
    "2. **Analytical:**\n",
    "   - Extend model to include variance shifts\n",
    "   - Incorporate additional market indicators\n",
    "   - Develop real-time change point detection\n",
    "\n",
    "3. **Strategic:**\n",
    "   - Use regime identification for portfolio optimization\n",
    "   - Develop scenario analysis based on historical regimes\n",
    "   - Integrate findings into decision-making processes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
